{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Create a Bi-LSTEM Model with Attention for Bias & for Tone/Bias Analysis\n",
        "## For Framing Analysis Project by Shreya and Jennifer"
      ],
      "metadata": {
        "id": "YLZvcxewYUyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx0zLI8yU2Ah",
        "outputId": "43b9ad9d-00c6-41fd-fdc3-8a4059737ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                                               title  first_tone_annotation  \\\n",
            "0  A Set of Borders to Cross; For Children Seekin...                  17.35   \n",
            "1                   LAY OFF THE GUEST WORKER WE WANT                  17.35   \n",
            "2  Would ban on renting to illegals make sense here?                  19.35   \n",
            "3     Immigrants Pull Weight In Economy, Study Finds                  17.35   \n",
            "4                              The Citizenship Surge                  17.35   \n",
            "\n",
            "   first_framing_annotation  \n",
            "0                      10.2  \n",
            "1                       1.2  \n",
            "2                       5.2  \n",
            "3                       1.2  \n",
            "4                       2.2  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/''ISM 6564 - Text Analytics''/''Frame Analysis''/Training_Data.csv') #Change MyDrive to the correct path if needed\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['first_tone_annotation'] = df['first_tone_annotation'].astype(str)\n"
      ],
      "metadata": {
        "id": "QQ26PpGIZLBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing values in training set\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9ruJz81LcQYd",
        "outputId": "cff5daee-0311-4cda-b126-ec7f34cac57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title                        79\n",
              "first_tone_annotation         0\n",
              "first_framing_annotation    552\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_tone_annotation</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_framing_annotation</th>\n",
              "      <td>552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: drop from dataframe where there are no titles\n",
        "\n",
        "df = df.dropna(subset=['title'])"
      ],
      "metadata": {
        "id": "oI2-pv_KcYAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tidy dataset for bias\n",
        "\n",
        "# Create a new DataFrame with no missing 'first_tone_annotation' values\n",
        "df_no_missing_tone = df.dropna(subset=['first_tone_annotation'])\n",
        "df_no_missing_tone = df_no_missing_tone[df_no_missing_tone['first_tone_annotation'] != 'nan']\n",
        "\n",
        "# Create another DataFrame containing only 'title' and 'first_tone_annotation' columns\n",
        "df_title_tone = df_no_missing_tone[['title', 'first_tone_annotation']]"
      ],
      "metadata": {
        "id": "cWbha9fOcjHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_title_tone['first_tone_annotation'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybWk3ETiFEU",
        "outputId": "ba460a09-bcc9-470d-a346-5a3ccc150454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['17.35', '19.35', '18.3', '17.4', '19.4'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "possible_labels = df_title_tone['first_tone_annotation'].unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiI9atQthQtM",
        "outputId": "77c85c4d-ea6a-49c4-eae4-bc9649d54db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'17.35': 0, '19.35': 1, '18.3': 2, '17.4': 3, '19.4': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add a column to the dataframe with the numerical labels\n",
        "df_title_tone['label'] = df_title_tone['first_tone_annotation'].replace(label_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeWPa8TOieMT",
        "outputId": "add59a21-c812-4c7e-89ca-680423ab4217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-c7552a5acff7>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_title_tone['label'] = df_title_tone['first_tone_annotation'].replace(label_dict)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "# Sample text data and target values\n",
        "text_data = df_title_tone['title'].tolist() # Call the tolist() method to get the actual list of titles\n",
        "numeric_labels = np.array(df_title_tone['label'])  # Use the correct column for numeric labels\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_data, numeric_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Tokenization for Keras and pre-trained embeddings\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "max_length = 10  # Set max sequence length\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
        "\n",
        "\n",
        "# Embedding dimensions\n",
        "embedding_dim = 100\n",
        "\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "embedding_index = {}\n",
        "glove_file_path = '/content/drive/MyDrive/''ISM 6564 - Text Analytics''/''Frame Analysis''/glove.6B.100d.txt'  # Update this path with your local GloVe file path\n",
        "with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefficients = np.array(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefficients\n",
        "\n",
        "# Create embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "MOMDJe0Z0CD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional, Dense, Input, LSTM, Embedding, Multiply, Permute, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Define an attention layer\n",
        "def attention_layer(inputs):\n",
        "    # Compute the attention scores\n",
        "    attention = Dense(1, activation='tanh')(inputs)\n",
        "    attention = tf.keras.layers.Flatten()(attention)\n",
        "    attention = tf.keras.layers.Activation('softmax')(attention)\n",
        "    attention = tf.keras.layers.RepeatVector(100)(attention)\n",
        "    attention = Permute([2, 1])(attention)\n",
        "\n",
        "    # Apply attention weights\n",
        "    output_attention = Multiply()([inputs, attention])\n",
        "    return Lambda(lambda x: K.sum(x, axis=1))(output_attention)\n",
        "\n",
        "# Define model with Bidirectional LSTM and attention\n",
        "input_layer = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)(input_layer)\n",
        "bi_lstm_layer = Bidirectional(LSTM(50, return_sequences=True))(embedding_layer)\n",
        "\n",
        "# Apply the attention layer\n",
        "attention_output = attention_layer(bi_lstm_layer)\n",
        "\n",
        "# Final dense layers\n",
        "output_layer = Dense(1)(attention_output)\n",
        "\n",
        "# Build and compile the model\n",
        "model_bi_lstm_attention = Model(inputs=input_layer, outputs=output_layer)\n",
        "model_bi_lstm_attention.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_bi_lstm_attention.summary()\n",
        "\n",
        "# Train and evaluate\n",
        "model_bi_lstm_attention.fit(X_train_pad, y_train, epochs=10, batch_size=32, verbose=2, validation_data=(X_test_pad, y_test))\n",
        "bi_lstm_attention_eval = model_bi_lstm_attention.evaluate(X_test_pad, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "36P3n5_re9J6",
        "outputId": "78e461a2-1ea2-4fa3-f52e-c92f6357e451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m643,100\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m60,400\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m101\u001b[0m │ bidirectional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ repeat_vector_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ permute_3 (\u001b[38;5;33mPermute\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ repeat_vector_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_3 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ bidirectional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ permute_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m101\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">643,100</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ repeat_vector_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ permute_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ repeat_vector_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ permute_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m703,702\u001b[0m (2.68 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">703,702</span> (2.68 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,602\u001b[0m (236.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,602</span> (236.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m643,100\u001b[0m (2.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">643,100</span> (2.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "110/110 - 5s - 47ms/step - loss: 1.4839 - val_loss: 1.2702\n",
            "Epoch 2/10\n",
            "110/110 - 1s - 6ms/step - loss: 1.2553 - val_loss: 1.2598\n",
            "Epoch 3/10\n",
            "110/110 - 1s - 6ms/step - loss: 1.1885 - val_loss: 1.2205\n",
            "Epoch 4/10\n",
            "110/110 - 1s - 6ms/step - loss: 1.1390 - val_loss: 1.2228\n",
            "Epoch 5/10\n",
            "110/110 - 1s - 6ms/step - loss: 1.0966 - val_loss: 1.2300\n",
            "Epoch 6/10\n",
            "110/110 - 1s - 6ms/step - loss: 1.0540 - val_loss: 1.2189\n",
            "Epoch 7/10\n",
            "110/110 - 1s - 6ms/step - loss: 0.9950 - val_loss: 1.2448\n",
            "Epoch 8/10\n",
            "110/110 - 1s - 6ms/step - loss: 0.9277 - val_loss: 1.2666\n",
            "Epoch 9/10\n",
            "110/110 - 1s - 6ms/step - loss: 0.8621 - val_loss: 1.2771\n",
            "Epoch 10/10\n",
            "110/110 - 1s - 6ms/step - loss: 0.7925 - val_loss: 1.3281\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate accuracy and microaccuracy for the model\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model_bi_lstm_attention.predict(X_test_pad)\n",
        "\n",
        "# Convert predicted probabilities to class labels (assuming a threshold of 0.5)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Calculate micro-averaged accuracy (useful for imbalanced datasets)\n",
        "# In this specific case, with a binary classification problem, accuracy and micro-average are the same.\n",
        "# For multi-class problems, micro-averaging aggregates across all classes.\n",
        "# For multi-class problems, micro-averaging will be different than the overall accuracy.\n",
        "cm = confusion_matrix(y_test, y_pred_labels)\n",
        "micro_accuracy = np.trace(cm) / np.sum(cm)\n",
        "print(f\"Micro-Averaged Accuracy: {micro_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TQYuqR0fKRU",
        "outputId": "7ab4f22c-72ca-4a14-f81c-d972ce5264ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "Accuracy: 0.36\n",
            "Micro-Averaged Accuracy: 0.36\n"
          ]
        }
      ]
    }
  ]
}